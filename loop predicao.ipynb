{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset ANP\n",
    "[gov.br: dados abertos](https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/acervo-de-dados-tecnicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Banco de dados:\n",
    "1. Cruzamento de dados de geolocalização da ANP com dados de produtividade mensal\n",
    "2. Seleção do do campo de Jubarte, na Bacia de Campos\n",
    "3. Append nas tabelas de produção mensal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerações:\n",
    "* Objeto de estudo: Bacia de Campos, campo de Jubarte\n",
    "* Dados mensais ANP até dez23\n",
    "* Produtividade, Horas Trabalhadas > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sympy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import feyn\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe dados de Predição\n",
    "Bacia de Campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bacia',\n",
       " 'Poco',\n",
       " 'Campo',\n",
       " 'Periodo',\n",
       " 'Petroleo (bbl/dia)',\n",
       " 'Tempo de producao (h/mes)',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Dummy_repeticao',\n",
       " 'Days',\n",
       " 'MesProducao',\n",
       " 'Produtividade',\n",
       " 'DeltaProdutividade']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_analise = r\"C:\\Users\\guilh\\OneDrive - UFRGS\\Graduação\\10-Trabalho de Conclusão do Curso\\Predição de Poços de Petróleo\\Pocos\\analise.xlsx\"\n",
    "sheet_analise = 'campos'\n",
    "\n",
    "df_campos = pd.read_excel(file_analise, sheet_name=sheet_analise)\n",
    "df_campos.sort_values(by=['Campo', 'Periodo'], inplace=True)\n",
    "\n",
    "df_campos.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção do campo analisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Campo\n",
       "JUBARTE         1374\n",
       "MARLIM LESTE     303\n",
       "CARATINGA         66\n",
       "BARRACUDA         42\n",
       "MARLIM            41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campos_frequentes = df_campos['Campo'].value_counts().nlargest(5)\n",
    "campos_frequentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campos.loc[df_campos['MesProducao'] < 0, 'MesProducao'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Poco\n",
       "7BFR7ESS         98\n",
       "7JUB57DPAESS     97\n",
       "7JUB58DPAESS     97\n",
       "7BAZ8ESS         97\n",
       "8JUB39ESS        93\n",
       "7BFR12PAESS      91\n",
       "6BRSA631DBESS    90\n",
       "7BAZ4ESS         89\n",
       "7JUB34HESS       87\n",
       "6BRSA1222AESS    83\n",
       "7BAZ3ESS         83\n",
       "6BRSA639ESS      81\n",
       "7JUB44ESS        70\n",
       "7JUB55ESS        63\n",
       "7BAZ9HAESS       43\n",
       "7JUB45ESS        41\n",
       "7BAZ6ESS         29\n",
       "7BAZ10DAESS      27\n",
       "8JUB59DESS       11\n",
       "7JUB63ESS         3\n",
       "7JUB36ESS         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campo_analise = 'JUBARTE'\n",
    "df_campo_analise = df_campos[df_campos['Campo'] == campo_analise]\n",
    "\n",
    "df_campo_analise['Poco'].value_counts().nlargest(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desvios = 2\n",
    "mean = df_campo_analise['DeltaProdutividade'].mean()\n",
    "stdev = df_campo_analise['DeltaProdutividade'].std()\n",
    "\n",
    "lower_limit = mean - (desvios * stdev)\n",
    "upper_limit = mean + (desvios * stdev)\n",
    "\n",
    "df_campo_analise.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_campo_analise = df_campo_analise[(df_campo_analise['DeltaProdutividade'] >= lower_limit) & (df_campo_analise['DeltaProdutividade'] <= upper_limit)]\n",
    "\n",
    "df_campo_analise.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Latitude', 'Longitude', 'MesProducao', 'Produtividade']\n",
      "STDev: 268.06631759184836\n"
     ]
    }
   ],
   "source": [
    "colunas_analise = [ 'Latitude',\n",
    "                    'Longitude',\n",
    "                    'MesProducao',\n",
    "                    'Produtividade'\n",
    "]\n",
    "\n",
    "variavel_dependente = 'Produtividade'\n",
    "\n",
    "variaveis_independentes = [ 'Latitude',\n",
    "                            'Longitude', \n",
    "                            'MesProducao'\n",
    "]\n",
    "\n",
    "df_campo_analise = df_campo_analise[colunas_analise]\n",
    "print(df_campo_analise.columns.tolist())\n",
    "\n",
    "print('STDev:', df_campo_analise['Produtividade'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 200 concluída\n",
      "Resultados arquivados\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feyn import QLattice\n",
    "import feyn.tools\n",
    "import pandas as pd\n",
    "\n",
    "# Parâmetros do TensorFlow\n",
    "l1_value = l2_value = 0.001\n",
    "fator_dropout = 0.2\n",
    "funcao_ativacao = 'relu'\n",
    "neuronios_por_camada = 256\n",
    "batches = 32\n",
    "\n",
    "# Inicialização QLattice\n",
    "ql = QLattice()\n",
    "\n",
    "# Lista de resultados (inicialização vazia)\n",
    "results_list = []\n",
    "\n",
    "# Loop conjunto para todos os algoritmos\n",
    "for i in range(200):\n",
    "    # Scaling + Split do dataset (reformata o dataset a cada iteração do loop)\n",
    "    scaler = StandardScaler()\n",
    "    df_features_scaled = scaler.fit_transform(df_campo_analise[['Latitude', 'Longitude', 'MesProducao']])\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_features_scaled, df_campo_analise['Produtividade'], train_size=0.70, test_size=0.30)\n",
    "    \n",
    "    # Rede Neural Artificial\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(3,)),\n",
    "        tf.keras.layers.Dense(neuronios_por_camada, activation=funcao_ativacao, kernel_regularizer=tf.keras.regularizers.l2(l2=l2_value)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(fator_dropout),\n",
    "        tf.keras.layers.Dense(neuronios_por_camada, activation=funcao_ativacao, kernel_regularizer=tf.keras.regularizers.l2(l2=l2_value)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(fator_dropout),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    otimizador = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=otimizador, loss='mean_squared_error')\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(x_train, y_train, \n",
    "              epochs=200,\n",
    "              verbose=0,\n",
    "              batch_size=batches,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    y_pred_test_tf = model.predict(x_test)\n",
    "\n",
    "    test_r2_tf = r2_score(y_test, y_pred_test_tf)\n",
    "    test_rmse_tf = root_mean_squared_error(y_test, y_pred_test_tf)\n",
    "    test_mae_tf = mean_absolute_error(y_test, y_pred_test_tf)\n",
    "\n",
    "    # Regressão Simbólica\n",
    "    train_feyn = pd.DataFrame(x_train, columns=['Latitude', 'Longitude', 'MesProducao'])\n",
    "    train_feyn['Produtividade'] = y_train.values\n",
    "\n",
    "    test_feyn = pd.DataFrame(x_test, columns=['Latitude', 'Longitude', 'MesProducao'])\n",
    "    test_feyn['Produtividade'] = y_test.values\n",
    "\n",
    "    models = ql.auto_run(data=train_feyn, output_name='Produtividade')\n",
    "    best = models[0]\n",
    "\n",
    "    y_true_feyn = test_feyn['Produtividade'].values\n",
    "    y_pred_feyn = best.predict(test_feyn)\n",
    "\n",
    "    test_r2_feyn = r2_score(y_true_feyn, y_pred_feyn)\n",
    "    test_rmse_feyn = root_mean_squared_error(y_true_feyn, y_pred_feyn)\n",
    "    test_mae_feyn = mean_absolute_error(y_true_feyn, y_pred_feyn)\n",
    "\n",
    "    # Regressão Linear\n",
    "    modelo_linear = LinearRegression()\n",
    "    modelo_linear.fit(x_train, y_train)\n",
    "\n",
    "    y_test_pred_linear = modelo_linear.predict(x_test)\n",
    "\n",
    "    test_r2_linear = r2_score(y_test, y_test_pred_linear)\n",
    "    test_rmse_linear = root_mean_squared_error(y_test, y_test_pred_linear)\n",
    "    test_mae_linear = mean_absolute_error(y_test, y_test_pred_linear)\n",
    "\n",
    "    # Regressão Polinomial\n",
    "    modelo_poli = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2)),\n",
    "        ('linear', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    modelo_poli.fit(x_train, y_train)\n",
    "\n",
    "    y_test_pred_poli = modelo_poli.predict(x_test)\n",
    "\n",
    "    test_r2_poli = r2_score(y_test, y_test_pred_poli)\n",
    "    test_rmse_poli = root_mean_squared_error(y_test, y_test_pred_poli)\n",
    "    test_mae_poli = mean_absolute_error(y_test, y_test_pred_poli)\n",
    "\n",
    "    # Armazenamento\n",
    "    results_list.append({\n",
    "        'n treinamento': i+1, \n",
    "        'r2_tensorflow': test_r2_tf, \n",
    "        'mae_tensorflow': test_mae_tf, \n",
    "        'rmse_tensorflow': test_rmse_tf,\n",
    "        'r2_feyn': test_r2_feyn, \n",
    "        'mae_feyn': test_mae_feyn, \n",
    "        'rmse_feyn': test_rmse_feyn,\n",
    "        'r2_linear': test_r2_linear, \n",
    "        'mae_linear': test_mae_linear, \n",
    "        'rmse_linear': test_rmse_linear,\n",
    "        'r2_poli': test_r2_poli, \n",
    "        'mae_poli': test_mae_poli, \n",
    "        'rmse_poli': test_rmse_poli\n",
    "    })\n",
    "    print(f\"Iteração {i+1} concluída\")\n",
    "\n",
    "unified_results = pd.DataFrame(results_list)\n",
    "unified_results.to_excel(r'C:\\Users\\guilh\\OneDrive - UFRGS\\Graduação\\10-Trabalho de Conclusão do Curso\\Predição de Poços de Petróleo\\unified_results.xlsx', index=False)\n",
    "print(\"Resultados arquivados\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
